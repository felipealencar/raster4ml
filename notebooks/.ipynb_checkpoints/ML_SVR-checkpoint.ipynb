{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "639590e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "os.chdir(r\"F:\\planetseed\")\n",
    "\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import random as python_random\n",
    "from numpy.polynomial.polynomial import polyfit\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.cross_decomposition import PLSRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3900deb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "font = {'family' : 'Arial',\n",
    "        'weight' : 'normal',\n",
    "        'size'   : 7}\n",
    "matplotlib.rc('font', **font)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "444a8030",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5b7e9f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Protein Oil Sucrose Fiber Starch Ash Comp_Carb Simp_Carb\n",
    "y_var = 'Simp_Carb'\n",
    "remarks = f'SVR {y_var}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a3bf21a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "H1G_2017_VI = pd.read_csv(r\".\\data\\csv_V3\\2017_H1G_VI.csv\", index_col=0)\n",
    "H1G_2020_VI = pd.read_csv(r\".\\data\\csv_V3\\2020_H1G_VI.csv\", index_col=0)\n",
    "H1G_2021_VI = pd.read_csv(r\".\\data\\csv_V3\\2021_H1G_VI.csv\", index_col=0)\n",
    "L2_2021_VI = pd.read_csv(r\".\\data\\csv_V3\\2021_L2_VI.csv\", index_col=0)\n",
    "\n",
    "H1G_2017_TX = pd.read_csv(r\".\\data\\csv_V3\\2017_H1G_TX.csv\", index_col=0)\n",
    "H1G_2020_TX = pd.read_csv(r\".\\data\\csv_V3\\2020_H1G_TX.csv\", index_col=0)\n",
    "H1G_2021_TX = pd.read_csv(r\".\\data\\csv_V3\\2021_H1G_TX.csv\", index_col=0)\n",
    "L2_2021_TX = pd.read_csv(r\".\\data\\csv_V3\\2021_L2_TX.csv\", index_col=0)\n",
    "\n",
    "H1G_2017_y = pd.read_csv(r\".\\data\\csv_V3\\2017_H1G_Target.csv\", index_col=0)[y_var] \n",
    "H1G_2020_y = pd.read_csv(r\".\\data\\csv_V3\\2020_H1G_Target.csv\", index_col=0)[y_var] \n",
    "H1G_2021_y = pd.read_csv(r\".\\data\\csv_V3\\2021_H1G_Target.csv\", index_col=0)[y_var] \n",
    "L2_2021_y = pd.read_csv(r\".\\data\\csv_V3\\2021_L2_Target.csv\", index_col=0)[y_var] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5c7651c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "VI_data = pd.concat([H1G_2017_VI, H1G_2020_VI, H1G_2021_VI, L2_2021_VI])\n",
    "TX_data = pd.concat([H1G_2017_TX, H1G_2020_TX, H1G_2021_TX, L2_2021_TX])\n",
    "y_data = pd.DataFrame(pd.concat([H1G_2017_y, H1G_2020_y, H1G_2021_y, L2_2021_y]))\n",
    "all_data = pd.concat([y_data, VI_data, TX_data], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4f13b7ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = all_data.dropna()\n",
    "\n",
    "#VI_data = all_data.iloc[:, 1:295]\n",
    "VI_data = all_data.iloc[:, 1:]\n",
    "#TX_data = all_data.iloc[:, 295:]\n",
    "y_data = all_data.iloc[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "53959936",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_importance(data_X, data_y, n_featuers):\n",
    "    \n",
    "    # Train test split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(data_X, data_y, test_size=0.25, random_state=35)\n",
    "\n",
    "    # Define a linear regression model\n",
    "    perm_model = Pipeline([('scaler', MinMaxScaler()), ('model', LinearRegression())])\n",
    "    perm_model.fit(X_train, y_train)\n",
    "\n",
    "    #Perform a permutaion feature importance model\n",
    "    result = permutation_importance(perm_model, X_train, y_train, n_repeats=500, random_state=42, n_jobs=-1)\n",
    "\n",
    "    # get importance\n",
    "    importance = result.importances_mean\n",
    "\n",
    "    imp_feats = pd.DataFrame(importance, index=data_X.columns, columns=['Importance'])\n",
    "\n",
    "    # Sort the dataframe so the important features are on the top\n",
    "    imp_feats = imp_feats.sort_values(by=['Importance'], ascending=False)\n",
    "\n",
    "    # Take the first 20 features\n",
    "    imp_feats_20 = imp_feats.iloc[:n_featuers, :]\n",
    "\n",
    "    # Only take the important features and return the whole data\n",
    "    df = data_X[imp_feats_20.index]\n",
    "\n",
    "    #plt.figure(dpi=150)\n",
    "    #plt.barh(imp_feats_20.index, imp_feats_20['Importance'])\n",
    "    #plt.show()\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b6c81101",
   "metadata": {},
   "outputs": [],
   "source": [
    "VI_data_X_imp = feature_importance(VI_data, y_data, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0ede5e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X_VI, test_X_VI = train_test_split(VI_data_X_imp, test_size=0.25, random_state=35)\n",
    "train_y, test_y = train_test_split(y_data, test_size=0.25, random_state=35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "71ffb6ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(319, 30)\n",
      "(107, 30)\n",
      "(319,)\n",
      "(107,)\n"
     ]
    }
   ],
   "source": [
    "print(train_X_VI.shape)\n",
    "print(test_X_VI.shape)\n",
    "print(train_y.shape)\n",
    "print(test_y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "446386f3",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "71717f42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 4.81 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score=nan,\n",
       "             estimator=Pipeline(memory=None,\n",
       "                                steps=[('scaler',\n",
       "                                        MinMaxScaler(copy=True,\n",
       "                                                     feature_range=(0, 1))),\n",
       "                                       ('model',\n",
       "                                        SVR(C=1.0, cache_size=200, coef0=0.0,\n",
       "                                            degree=3, epsilon=0.1,\n",
       "                                            gamma='scale', kernel='rbf',\n",
       "                                            max_iter=-1, shrinking=True,\n",
       "                                            tol=0.001, verbose=False))],\n",
       "                                verbose=False),\n",
       "             iid='deprecated', n_jobs=4,\n",
       "             param_grid={'model__C': [0.0009765625, 0.001953125, 0.00390625,\n",
       "                                      0.0078125, 0.015625, 0.03125, 0.0625,\n",
       "                                      0.125, 0.25, 0.5, 1.0, 2.0, 4.0, 8.0,\n",
       "                                      16.0, 32.0, 64.0],\n",
       "                         'model__gamma': [0.0009765625, 0.001953125, 0.00390625,\n",
       "                                          0.0078125, 0.015625, 0.03125, 0.0625,\n",
       "                                          0.125, 0.25, 0.5, 1.0, 2.0, 4.0, 8.0,\n",
       "                                          16.0, 32.0, 64.0]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "#SVR\n",
    "\n",
    "# Define pipeline\n",
    "pipe = Pipeline(steps=[('scaler', MinMaxScaler()),\n",
    "                       ('model', SVR())])\n",
    "\n",
    "# Define pipeline parameters\n",
    "param = {'model__gamma': [2**i for i in np.arange(-10, 7, 1, dtype='float')],\n",
    "         'model__C': [2**i for i in np.arange(-10, 7, 1, dtype='float')]}\n",
    "\n",
    "# Define grid\n",
    "grid = GridSearchCV(estimator=pipe,\n",
    "                    param_grid=param,\n",
    "                    cv=5,\n",
    "                    n_jobs=4)\n",
    "grid.fit(train_X_VI, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c888e1af",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = str(int(time.time()))\n",
    "model_dir = os.path.join(r\".\\models\", model_id)\n",
    "os.makedirs(model_dir, exist_ok=True)\n",
    "model_file_name = os.path.join(model_dir, f\"model_{model_id}.pkl\")\n",
    "\n",
    "# Save model\n",
    "pickle.dump(grid, open(model_file_name, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2bb00720",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict\n",
    "train_y_pred = grid.predict(train_X_VI)\n",
    "test_y_pred = grid.predict(test_X_VI)\n",
    "\n",
    "train_y = np.array(train_y)\n",
    "test_y = np.array(test_y)\n",
    "\n",
    "train_y_pred = np.array(train_y_pred).reshape(-1)\n",
    "test_y_pred = np.array(test_y_pred).reshape(-1)\n",
    "\n",
    "# Save actual and predicted y\n",
    "y_summary = pd.DataFrame(np.vstack((test_y, test_y_pred)).T,\n",
    "                         columns=['Measured', 'Predicted'])\n",
    "y_summary.to_csv(os.path.join(model_dir, 'y_summary.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6c0e3575",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function that calcualte error metrics from predicted and actual values\n",
    "def reg_model_metrics(actual, pred):\n",
    "    MSE = mean_squared_error(actual, pred)\n",
    "    RMSE = np.sqrt(MSE)\n",
    "    actual_mean = np.mean(actual)\n",
    "    RRMSE = 100*(RMSE/actual_mean)\n",
    "    R2 = np.square(np.corrcoef(actual, pred)[0, 1])# r2_score(actual, pred)\n",
    "    return RMSE, RRMSE, R2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6ef6e03d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate metrics\n",
    "RMSE_train, RRMSE_train, R2_train = reg_model_metrics(train_y, train_y_pred)\n",
    "RMSE_test, RRMSE_test, R2_test = reg_model_metrics(test_y, test_y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8fe563e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update the main result vault\n",
    "\n",
    "# Read it\n",
    "result_vault = pd.read_csv(r\".\\models\\_results.csv\")\n",
    "\n",
    "# Create a new result dataframe that needs to be appended\n",
    "result_vault_updt = pd.DataFrame(data=[[model_id, y_var, \"NA\", \"NA\",\n",
    "                                        R2_test, R2_train, RRMSE_test, RRMSE_train, remarks]],\n",
    "                                 columns=result_vault.columns)\n",
    "\n",
    "# Update it\n",
    "result_vault_new = pd.concat([result_vault, result_vault_updt])\n",
    "\n",
    "# Save it\n",
    "result_vault_new.to_csv(r\".\\models\\_results.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd47944a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
